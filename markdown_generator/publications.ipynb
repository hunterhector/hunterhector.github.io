{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\ttitle\tvenue\texcerpt\turl_slug\tpaper_url\tproject_url\r",
      "\r\n",
      "2011-11-14\tPolyUCOMP in TAC 2011 Entity Linking and Slot-Filling\tIn Proceedings of the Fourth Text Analysis Conference (TAC 2011).\tThis paper describes PolyUCOMP team's approach to the TAC-KBP 2011 Entity LInking and Slot Filling tasks\ttac2011\thttps://hunterhector.github.io/files/papers/Jian_et_al._-_2011_-_Proceedings_of_the_Fourth_Text_Analysis_Conference_(TAC_2011).pdf\t\r",
      "\r\n",
      "2011-07-24\tHigh Performance Clustering for Web Person Name Disambiguation Using Topic Capturing\tSIGIR2011 Workshop on Entity Orientation Search\tWe identify a topic drift problem in clustering web person name disambiguation and propose a fix by maintaining the topic words.\tsigir2011\thttps://hunterhector.github.io/files/papers/Liu,_Lu,_Xu_-_2011_-_The_first_International_Workshop_on_Entity_Orientation_Search,_SIGIR2011_Workshop.pdf\t\r",
      "\r\n",
      "2012-01-01\tAggregating skip bigrams into key phrase-based vector space model for web person disambiguation.\tKONVENS 2012\t\tkonvens2012\thttps://hunterhector.github.io/files/papers/Xu,_Lu,_Liu_-_2012_-_Proceedings_of_KONVENS_2012.pdf\t\r",
      "\r\n",
      "2018-01-13\tGraph-Based Decoding for Event Sequencing and Coreference Resolution\t7th International Conference on Computational Linguistics(COLING 2018)\t\tcoling2018\thttp://arxiv.org/abs/1806.05099\t\r",
      "\r\n",
      "2018-09-03\tAutomatic Event Salience Identification\tEMNLP 2018\t\temnlp2018\thttp://arxiv.org/abs/1809.00647\t\r",
      "\r\n",
      "2017-11-13\tMulti-lingual Extraction and Integration of Entities, Relations, Events and Sentiments into ColdStart++ KBs with the SAFT System\tTAC 2017\t\ttac2017\thttps://tac.nist.gov/publications/2017/participant.papers/TAC2017.SAFT_ISI.proceedings.pdf\t\r",
      "\r\n",
      "2017-11-13\tEvents Detection, Coreference and Sequencing: Whatâ€™s next? Overview of the TAC KBP 2017 Event Track.\tTAC 2017\t\ttac2017\thttps://tac.nist.gov/publications/2017/presentations/TAC2017.KBP.EN.overview.presentation.pdf\t\r",
      "\r\n",
      "2018-03-03\tTowards Better Text Understanding and Retrieval through Kernel Entity Salience Modeling\tSIGIR 2018\t\tsigir2018\thttps://doi.org/10.1145/3209978.3209982\thttp://boston.lti.cs.cmu.edu/appendices/SIGIR2018-KESM/\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>url_slug</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>project_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-14</td>\n",
       "      <td>PolyUCOMP in TAC 2011 Entity Linking and Slot-...</td>\n",
       "      <td>In Proceedings of the Fourth Text Analysis Con...</td>\n",
       "      <td>This paper describes PolyUCOMP team's approach...</td>\n",
       "      <td>tac2011</td>\n",
       "      <td>https://hunterhector.github.io/files/papers/Ji...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-24</td>\n",
       "      <td>High Performance Clustering for Web Person Nam...</td>\n",
       "      <td>SIGIR2011 Workshop on Entity Orientation Search</td>\n",
       "      <td>We identify a topic drift problem in clusterin...</td>\n",
       "      <td>sigir2011</td>\n",
       "      <td>https://hunterhector.github.io/files/papers/Li...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>Aggregating skip bigrams into key phrase-based...</td>\n",
       "      <td>KONVENS 2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>konvens2012</td>\n",
       "      <td>https://hunterhector.github.io/files/papers/Xu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>Graph-Based Decoding for Event Sequencing and ...</td>\n",
       "      <td>7th International Conference on Computational ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coling2018</td>\n",
       "      <td>http://arxiv.org/abs/1806.05099</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>Automatic Event Salience Identification</td>\n",
       "      <td>EMNLP 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>emnlp2018</td>\n",
       "      <td>http://arxiv.org/abs/1809.00647</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>Multi-lingual Extraction and Integration of En...</td>\n",
       "      <td>TAC 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tac2017</td>\n",
       "      <td>https://tac.nist.gov/publications/2017/partici...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>Events Detection, Coreference and Sequencing: ...</td>\n",
       "      <td>TAC 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tac2017</td>\n",
       "      <td>https://tac.nist.gov/publications/2017/present...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-03-03</td>\n",
       "      <td>Towards Better Text Understanding and Retrieva...</td>\n",
       "      <td>SIGIR 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sigir2018</td>\n",
       "      <td>https://doi.org/10.1145/3209978.3209982</td>\n",
       "      <td>http://boston.lti.cs.cmu.edu/appendices/SIGIR2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pub_date                                              title  \\\n",
       "0  2011-11-14  PolyUCOMP in TAC 2011 Entity Linking and Slot-...   \n",
       "1  2011-07-24  High Performance Clustering for Web Person Nam...   \n",
       "2  2012-01-01  Aggregating skip bigrams into key phrase-based...   \n",
       "3  2018-01-13  Graph-Based Decoding for Event Sequencing and ...   \n",
       "4  2018-09-03            Automatic Event Salience Identification   \n",
       "5  2017-11-13  Multi-lingual Extraction and Integration of En...   \n",
       "6  2017-11-13  Events Detection, Coreference and Sequencing: ...   \n",
       "7  2018-03-03  Towards Better Text Understanding and Retrieva...   \n",
       "\n",
       "                                               venue  \\\n",
       "0  In Proceedings of the Fourth Text Analysis Con...   \n",
       "1    SIGIR2011 Workshop on Entity Orientation Search   \n",
       "2                                       KONVENS 2012   \n",
       "3  7th International Conference on Computational ...   \n",
       "4                                         EMNLP 2018   \n",
       "5                                           TAC 2017   \n",
       "6                                           TAC 2017   \n",
       "7                                         SIGIR 2018   \n",
       "\n",
       "                                             excerpt     url_slug  \\\n",
       "0  This paper describes PolyUCOMP team's approach...      tac2011   \n",
       "1  We identify a topic drift problem in clusterin...    sigir2011   \n",
       "2                                                NaN  konvens2012   \n",
       "3                                                NaN   coling2018   \n",
       "4                                                NaN    emnlp2018   \n",
       "5                                                NaN      tac2017   \n",
       "6                                                NaN      tac2017   \n",
       "7                                                NaN    sigir2018   \n",
       "\n",
       "                                           paper_url  \\\n",
       "0  https://hunterhector.github.io/files/papers/Ji...   \n",
       "1  https://hunterhector.github.io/files/papers/Li...   \n",
       "2  https://hunterhector.github.io/files/papers/Xu...   \n",
       "3                    http://arxiv.org/abs/1806.05099   \n",
       "4                    http://arxiv.org/abs/1809.00647   \n",
       "5  https://tac.nist.gov/publications/2017/partici...   \n",
       "6  https://tac.nist.gov/publications/2017/present...   \n",
       "7            https://doi.org/10.1145/3209978.3209982   \n",
       "\n",
       "                                         project_url  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7  http://boston.lti.cs.cmu.edu/appendices/SIGIR2...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():    \n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = item.pub_date[:4]\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "    \n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "    \n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "    \n",
    "    md += \"\\ndate: \" + str(item.pub_date) \n",
    "    \n",
    "    md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "\n",
    "# Too many URL and ugly    \n",
    "#     if len(str(item.paper_url)) > 5:\n",
    "#         md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    \n",
    "#     md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "    \n",
    "    paper_url = '#'\n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        paper_url = item.paper_url\n",
    "        \n",
    "    project_url = '#'\n",
    "    if len(str(item.project_url)) > 5:\n",
    "        project_url = item.project_url\n",
    "        \n",
    "    md += \"\\n[Paper](\" + paper_url + \")\"\n",
    "    md += \" | \"\n",
    "    md += \"[Project Page](\" + project_url + \")\\n\"\n",
    "        \n",
    "#     md += \"\\nRecommended citation: \" + item.citation\n",
    "        \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "           \n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-07-24-sigir2011.md    2017-11-13-tac2017.md     2018-09-03-emnlp2018.md\r\n",
      "2011-11-14-tac2011.md\t   2018-01-13-coling2018.md\r\n",
      "2012-01-01-konvens2012.md  2018-03-03-sigir2018.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "title: \"Towards Better Text Understanding and Retrieval through Kernel Entity Salience Modeling\"\r\n",
      "collection: publications\r\n",
      "permalink: /publication/2018-03-03-sigir2018\r\n",
      "date: 2018-03-03\r\n",
      "venue: 'SIGIR 2018'\r\n",
      "---\r\n",
      "[Paper](https://doi.org/10.1145/3209978.3209982)[Project Page](http://boston.lti.cs.cmu.edu/appendices/SIGIR2018-KESM/)\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2018-03-03-sigir2018.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
